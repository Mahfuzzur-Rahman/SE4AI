import sys
import json
import time
import os
from pathlib import Path
from dotenv import load_dotenv

# --- 1. Dynamic Path Resolution ---
# Force Python to recognize the project root for internal imports
CURRENT_FILE = Path(__file__).resolve()
PROJECT_ROOT = CURRENT_FILE.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# --- 2. Load Environment Variables ---
# Automatically loads ANTHROPIC_API_KEY from your .env file
load_dotenv(PROJECT_ROOT / ".env")

# Import orchestration patterns from the local package
from orchestrations.centralized import centralized_graph
from orchestrations.hierarchical import hierarchical_graph
from orchestrations.decentralized import decentralized_graph
from orchestrations.hybrid import hybrid_graph

def run_benchmark(pattern_name: str, task_data: dict):
    """
    Executes a specific orchestration pattern and records performance metrics.
    """
    # Map pattern names to compiled LangGraph objects
    patterns = {
        "centralized": centralized_graph,
        "hierarchical": hierarchical_graph,
        "decentralized": decentralized_graph,
        "hybrid": hybrid_graph
    }
    
    if pattern_name not in patterns:
        print(f"Error: Orchestration pattern '{pattern_name}' not found.")
        return

    graph = patterns[pattern_name]

    # Initialize AgentState with FullStack-Bench task data
    initial_state = {
        "messages": [
            {
                "role": "user", 
                "content": [
                    {
                        "type": "text", 
                        "text": f"Task: {task_data.get('instruction', '')}",
                        "cache_control": {"type": "ephemeral"} # Cache the heavy task context
                    }
                ]
            }
        ],
        "usage_metadata": {"input_tokens": 0, "output_tokens": 0, "total_cost": 0.0},
        "start_time": time.time(),
        "turn_count": 0,
        "task_description": task_data.get("instruction", ""),
        "workspace_snapshot": {}, 
        "edit_history": {},
        "execution_status": "PENDING"
    }

    print(f"\n{'='*20} INITIATING: {pattern_name.upper()} {'='*20}")
    print(f"Task ID: {task_data.get('id', 'Unknown')}")

    # --- 3. Execution Layer ---
    try:
        # Authentication check happens during the first node call
        final_state = graph.invoke(initial_state)
        
        # Finalize timing for RQ 2
        final_state["end_time"] = time.time()
        duration = final_state["end_time"] - final_state["start_time"]
        
        # --- 4. Result Persistence ---
        results_dir = PROJECT_ROOT / "results"
        results_dir.mkdir(exist_ok=True)
        
        output_file = results_dir / f"{pattern_name}_run_results.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(final_state, f, indent=4, default=str)

        print(f"\n{'='*20} SUCCESS {'='*20}")
        print(f"Cost Incurred: ${final_state['usage_metadata']['total_cost']:.4f}")
        print(f"Total Turns:   {final_state['turn_count']}")
        print(f"Latency:       {duration:.2f}s")
        print(f"Metrics Log:   {output_file}")

    except Exception as e:
        print(f"\n[!] Execution Failed: {str(e)}")
        # Check if it was an Auth error to give the user a hint
        if "api_key" in str(e).lower():
            print("Hint: Check if your ANTHROPIC_API_KEY is correct in the .env file.")

if __name__ == "__main__":
    # Validate API Key before loading heavy data
    if not os.getenv("ANTHROPIC_API_KEY"):
        print("Critical Error: ANTHROPIC_API_KEY missing from .env or environment.")
        sys.exit(1)

    # Path to the dataset generated by convert_to_json.py
    dataset_path = PROJECT_ROOT / "data" / "dataset.json"
    
    if not dataset_path.exists():
        print(f"Error: Dataset not found at {dataset_path}. Run conversion script first.")
        sys.exit(1)

    # Load and execute on a single benchmark point
    with open(dataset_path, "r", encoding="utf-8") as f:
        dataset = json.load(f)

    # Testing on the first professional task
    run_benchmark("centralized", dataset[0])